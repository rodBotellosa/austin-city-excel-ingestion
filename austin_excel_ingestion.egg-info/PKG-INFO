Metadata-Version: 2.4
Name: austin-excel-ingestion
Version: 0.1.0
Summary: A Python tool for ingesting and parsing Excel documents
Author: Rodrigo Botello
Project-URL: Bug Reports, https://github.com/rodBotellosa/austin-city-excel-ingestion/issues
Project-URL: Source, https://github.com/rodBotellosa/austin-city-excel-ingestion
Keywords: excel parsing ingestion pandas
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Text Processing :: Markup
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: pandas>=2.2.0
Requires-Dist: openpyxl>=3.1.2
Requires-Dist: pydantic>=2.5.2
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: click>=8.1.7
Requires-Dist: rich>=13.7.0
Requires-Dist: typer>=0.9.0
Requires-Dist: loguru>=0.7.2
Requires-Dist: pyarrow>=14.0.2
Requires-Dist: regex>=2023.10.3
Dynamic: author
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: keywords
Dynamic: project-url
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# Austin City Excel Ingestion Tool

A Python tool for ingesting structured Excel files and converting them to JSON and Parquet formats with comprehensive metadata extraction.

## Features

- **Excel File Processing**: Reads structured Excel files with hierarchical data
- **Metadata Extraction**: Computes anchors, paths, parent relationships, and confidence scores
- **Reference Detection**: Automatically finds code references (Section, LDC, Title)
- **Multiple Output Formats**: JSONL and Parquet output support
- **Validation**: Comprehensive file structure validation
- **Rich CLI**: Beautiful terminal interface with progress indicators

## Installation

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Verify installation:
```bash
python -m src.main --help
```

## Usage

### Basic Ingestion

```bash
# Ingest Excel file with default settings
python -m src.main ingest data.xlsx

# Specify output prefix
python -m src.main ingest data.xlsx --output processed_data

# Output only JSONL format
python -m src.main ingest data.xlsx --format jsonl

# Output only Parquet format
python -m src.main ingest data.xlsx --format parquet
```

### Advanced Options

```bash
# Custom document ID
python -m src.main ingest data.xlsx --doc-id my_document

# Disable anchor normalization (keep trailing .0)
python -m src.main ingest data.xlsx --no-normalize-anchors

# Verbose logging
python -m src.main ingest data.xlsx --verbose
```

### File Validation

```bash
# Validate Excel file structure
python -m src.main validate data.xlsx

# Detailed validation with column statistics
python -m src.main validate data.xlsx --detailed
```

### File Preview

```bash
# Preview Excel file structure
python -m src.main preview data.xlsx

# Preview with more rows
python -m src.main preview data.xlsx --rows 10
```

## Input Format

The tool expects Excel files with the following columns:

| Column | Type | Required | Description |
|--------|------|----------|-------------|
| `NodeId` | String | Yes | Hierarchical identifier (e.g., "1", "1.2", "1.2.1") |
| `Title` | String | No | Section/heading title |
| `Subtitle` | String | No | Subheading/caption |
| `Content` | String | No | Body text for the node |
| `Url` | String | No | Web source URL |

### Example Excel Structure

| NodeId | Title | Subtitle | Content | Url |
|--------|-------|----------|---------|-----|
| 1 | General | | | |
| 1.1 | Purpose | | This section defines... | |
| 1.2.0 | Environmental Resource Inventory | | | https://example.com |
| 1.2.1 | Definitions | | Section 25-8-184 defines... | |

## Output Schema

Each row is converted to a structured JSON object:

```json
{
  "doc_id": "ecm",
  "anchor": "1.2.1",
  "node_id": "1.2.1",
  "title": "Definitions",
  "subtitle": null,
  "content": "Section 25-8-184 defines...",
  "url": null,
  "path": ["1", "1.2", "1.2.1"],
  "parent_anchor": "1.2",
  "block_type": "HEADING",
  "section_labels": {
    "section": "1",
    "chapter": "1.2",
    "subsection": "1.2.1"
  },
  "order": 1002001,
  "tokens": 0,
  "confidence": 0.95,
  "refs": [
    {
      "text": "25-8-184",
      "span": [8, 16],
      "type": "CODE"
    }
  ],
  "hash": "sha256:abc123...",
  "ingested_at": "2024-01-15T10:30:00.000Z",
  "source": {
    "type": "excel",
    "file": "data.xlsx"
  }
}
```

## Field Derivation

### Anchor & NodeId
- **NodeId**: Original hierarchical identifier as-is
- **Anchor**: Normalized NodeId (trailing .0 removed if configured)

### Path Generation
- **Path**: Cumulative segments from NodeId
- Example: `1.2.1.1` → `["1", "1.2", "1.2.1", "1.2.1.1"]`

### Block Type Detection
- **HEADING**: Title present, Content empty
- **PARA**: Content present, no title or mixed content
- **GLOSSARY**: Title/content contains glossary cues
- **TABLE**: Content contains table markup (| characters)

### Confidence Scoring
- **Base**: 0.9
- **Penalty**: -0.1 if both Title and Content empty
- **Boost**: +0.05 if Title matches known vocabulary
- **Range**: Clamped to [0, 1]

### Reference Detection
Automatically detects:
- `Section 25-8-184`
- `LDC 25-8-514`
- `Title 30-5-123`
- `§25-8-184`

### Order Calculation
Converts NodeId to sortable integer:
- `1.2.1.1` → `001002001001` → `1002001001`

## Configuration

### Heading Vocabulary
Default vocabulary for confidence scoring:
- Operating Permit
- Environmental Resource Inventory
- Interbasin Diversion
- Pollution Attenuation
- Resource Extraction
- Administrative
- General
- Definitions
- Glossary
- Appendix

### Output Formats

#### JSONL
- One JSON object per line
- Human-readable format
- Easy to process with standard tools

#### Parquet
- Columnar format
- Efficient for analytics
- Compressed storage

## Project Structure

```
austin-city-excel-ingestion/
├── src/
│   ├── __init__.py
│   ├── main.py              # CLI entry point
│   ├── models.py            # Pydantic data models
│   └── excel_parser.py      # Core parsing logic
├── requirements.txt         # Python dependencies
└── README.md               # This file
```

## Development

### Running Tests
```bash
# Install in development mode
pip install -e .

# Run tests (when implemented)
python -m pytest tests/
```

### Adding New Features
1. Extend `ExcelRow` model in `models.py`
2. Add parsing logic in `excel_parser.py`
3. Update CLI in `main.py`
4. Add tests

## Error Handling

The tool provides comprehensive error handling:
- **File validation**: Checks required columns and data types
- **Row processing**: Continues processing even if individual rows fail
- **Output validation**: Ensures generated data meets schema requirements
- **Detailed logging**: Verbose mode for debugging

## Performance

- **Memory efficient**: Processes rows one at a time
- **Fast parsing**: Optimized pandas operations
- **Parallel output**: Simultaneous JSONL and Parquet writing
- **Progress tracking**: Real-time progress indicators

## License

MIT License 
